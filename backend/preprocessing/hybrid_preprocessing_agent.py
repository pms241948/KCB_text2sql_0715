#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê·œì¹™ ê¸°ë°˜ + ë”•ì…”ë„ˆë¦¬ í˜¼í•© ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸
ì‹ ìš©í‰ê°€ ë„ë©”ì¸ íŠ¹í™” ìì—°ì–´ ì „ì²˜ë¦¬
"""

import re
import jieba
from typing import Dict, List, Tuple, Optional
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from services.dynamic_dictionary_manager import dictionary_manager

class HybridPreprocessingAgent:
    """ê·œì¹™ ê¸°ë°˜ + ë”•ì…”ë„ˆë¦¬ í˜¼í•© ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        self.dict_manager = dictionary_manager
        self._init_processing_rules()
        self._init_sql_patterns()
        self._init_entity_extractors()
    
    def _init_processing_rules(self):
        """ì „ì²˜ë¦¬ ê·œì¹™ ì´ˆê¸°í™”"""
        self.processing_rules = {
            # ë¬¸ì¥ ì •ê·œí™” ê·œì¹™
            "normalization": {
                "whitespace": r'\s+',
                "punctuation": r'[^\w\sê°€-í£]',
                "numbers": r'(\d+)',
                "currency": r'(\d+)(ì›|ë‹¬ëŸ¬|ì—”|ìœ„ì•ˆ)',
                "percentage": r'(\d+)%',
                "date_patterns": [
                    r'(\d{4})ë…„(\d{1,2})ì›”(\d{1,2})ì¼',
                    r'(\d{4})-(\d{1,2})-(\d{1,2})',
                    r'(\d{1,2})ì›”(\d{1,2})ì¼'
                ]
            },
            
            # ë„ë©”ì¸ íŠ¹í™” íŒ¨í„´
            "domain_patterns": {
                "credit_score_range": r'ì‹ ìš©ì ìˆ˜\s*(\d+)\s*ì´ìƒ',
                "risk_level": r'ìœ„í—˜ë„\s*(ë‚®ìŒ|ë³´í†µ|ë†’ìŒ)',
                "loan_amount": r'ëŒ€ì¶œê¸ˆì•¡\s*(\d+)ì›',
                "overdue_days": r'ì—°ì²´ì¼ìˆ˜\s*(\d+)ì¼',
                "customer_type": r'(ê°œì¸|ê¸°ì—…|ì†Œìƒê³µì¸)ê³ ê°',
                "vip_customer": r'VIP\s*ê³ ê°',
                "managed_customer": r'ê´€ë¦¬\s*ê³ ê°'
            },
            
            # ì¡°ê±´ë¶€ í‘œí˜„ íŒ¨í„´
            "conditional_patterns": {
                "if_then": r'ë§Œì•½\s*(.+?)\s*ì´ë©´\s*(.+?)\s*ì´ë‹¤',
                "when": r'(.+?)\s*ì¼\s*ë•Œ\s*(.+?)',
                "and_condition": r'(.+?)\s*ê·¸ë¦¬ê³ \s*(.+?)',
                "or_condition": r'(.+?)\s*ë˜ëŠ”\s*(.+?)',
                "not_condition": r'(.+?)\s*ì•„ë‹Œ\s*(.+?)'
            }
        }
    
    def _init_sql_patterns(self):
        """SQL íŒ¨í„´ ë§¤í•‘ - ë™ì  ë”•ì…”ë„ˆë¦¬ì—ì„œ ë¡œë“œ"""
        self.sql_patterns = self.dict_manager.sql_patterns
    
    def _init_entity_extractors(self):
        """ì—”í‹°í‹° ì¶”ì¶œê¸° ì´ˆê¸°í™”"""
        self.entity_extractors = {
            "credit_score": self._extract_credit_score,
            "risk_level": self._extract_risk_level,
            "loan_amount": self._extract_loan_amount,
            "customer_type": self._extract_customer_type,
            "date_range": self._extract_date_range,
            "numeric_range": self._extract_numeric_range
        }
    
    def preprocess_query(self, query: str) -> Dict:
        """ë©”ì¸ ì „ì²˜ë¦¬ í•¨ìˆ˜"""
        try:
            # 1ë‹¨ê³„: ê¸°ë³¸ ì •ê·œí™”
            normalized_query = self._normalize_text(query)
            
            # 2ë‹¨ê³„: ë„ë©”ì¸ íŠ¹í™” ë”•ì…”ë„ˆë¦¬ ë§¤í•‘
            mapped_query = self._apply_domain_mapping(normalized_query)
            
            # 3ë‹¨ê³„: ì—”í‹°í‹° ì¶”ì¶œ
            entities = self._extract_entities(normalized_query)
            
            # 4ë‹¨ê³„: ì ˆ(Clause) ì¶”ì¶œ
            clauses = self._extract_clauses(normalized_query)
            
            # 5ë‹¨ê³„: Chain of Thought ì¶”ë¡ 
            reasoning_chain = self._generate_reasoning_chain(normalized_query, entities, clauses)
            
            # 6ë‹¨ê³„: SQL íŒ¨í„´ ë§¤í•‘
            sql_mappings = self._map_sql_patterns(normalized_query)
            
            return {
                "original_query": query,
                "normalized_query": normalized_query,
                "mapped_query": mapped_query,
                "entities": entities,
                "clauses": clauses,
                "reasoning_chain": reasoning_chain,
                "sql_mappings": sql_mappings,
                "preprocessing_metadata": {
                    "domain_terms_found": len(entities.get("domain_terms", [])),
                    "clauses_count": len(clauses),
                    "reasoning_steps": len(reasoning_chain),
                    "sql_patterns_mapped": len(sql_mappings)
                }
            }
            
        except Exception as e:
            return {
                "error": f"ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "original_query": query
            }
    
    def _normalize_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ê·œí™”"""
        # ê³µë°± ì •ê·œí™”
        text = re.sub(self.processing_rules["normalization"]["whitespace"], ' ', text)
        
        # íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬ (í•œê¸€, ì˜ë¬¸, ìˆ«ì, ê¸°ë³¸ ë¬¸ì¥ë¶€í˜¸ë§Œ ìœ ì§€)
        text = re.sub(r'[^\w\sê°€-í£.,!?()]', '', text)
        
        # ìˆ«ì íŒ¨í„´ ì •ê·œí™”
        text = re.sub(r'(\d+)ì›', r'\1 ì›', text)
        text = re.sub(r'(\d+)%', r'\1 í¼ì„¼íŠ¸', text)
        
        return text.strip()
    
    def _apply_domain_mapping(self, text: str) -> str:
        """ë„ë©”ì¸ íŠ¹í™” ë”•ì…”ë„ˆë¦¬ ë§¤í•‘ ì ìš©"""
        mapped_text = text
        
        # ì‹ ìš©í‰ê°€ ë„ë©”ì¸ ìš©ì–´ ë§¤í•‘
        for category, terms in self.dict_manager.credit_terms.items():
            for term, info in terms.items():
                if term in mapped_text:
                    mapped_text = mapped_text.replace(term, info["sql_mapping"])
                
                # ë™ì˜ì–´ ë§¤í•‘
                for synonym in info.get("synonyms", []):
                    if synonym in mapped_text:
                        mapped_text = mapped_text.replace(synonym, info["sql_mapping"])
        
        return mapped_text
    
    def _extract_entities(self, text: str) -> Dict:
        """ì—”í‹°í‹° ì¶”ì¶œ"""
        entities = {
            "domain_terms": [],
            "numeric_values": [],
            "date_values": [],
            "customer_types": [],
            "risk_levels": [],
            "credit_scores": []
        }
        
        # ë„ë©”ì¸ ìš©ì–´ ì¶”ì¶œ
        for category, terms in self.dict_manager.credit_terms.items():
            for term, info in terms.items():
                if term in text or any(syn in text for syn in info.get("synonyms", [])):
                    entities["domain_terms"].append({
                        "term": term,
                        "category": category,
                        "sql_mapping": info.get("sql_mapping", term),
                        "table": info.get("table", "")
                    })
        
        # ìˆ«ì ê°’ ì¶”ì¶œ
        numeric_patterns = [
            r'(\d+)ì›',
            r'(\d+)%',
            r'(\d+)ì¼',
            r'(\d+)ê°œì›”',
            r'(\d+)ë…„'
        ]
        
        for pattern in numeric_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                entities["numeric_values"].append({
                    "value": match,
                    "pattern": pattern,
                    "type": "currency" if "ì›" in pattern else "percentage" if "%" in pattern else "duration"
                })
        
        # ê³ ê° ìœ í˜• ì¶”ì¶œ
        customer_types = ["ê°œì¸ê³ ê°", "ê¸°ì—…ê³ ê°", "ì†Œìƒê³µì¸", "VIPê³ ê°", "ê´€ë¦¬ê³ ê°"]
        for customer_type in customer_types:
            if customer_type in text:
                entities["customer_types"].append(customer_type)
        
        # ìœ„í—˜ë„ ë ˆë²¨ ì¶”ì¶œ
        risk_levels = ["ë‚®ìŒ", "ë³´í†µ", "ë†’ìŒ", "ë§¤ìš°ë‚®ìŒ", "ë§¤ìš°ë†’ìŒ"]
        for risk_level in risk_levels:
            if risk_level in text:
                entities["risk_levels"].append(risk_level)
        
        return entities
    
    def _extract_clauses(self, text: str) -> List[Dict]:
        """ì ˆ(Clause) ì¶”ì¶œ"""
        clauses = []
        processed_clauses = set()  # ì¤‘ë³µ ë°©ì§€
        
        # 1ë‹¨ê³„: ëª…í™•í•œ êµ¬ë¶„ìë¡œ ë¶„ë¦¬ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
        primary_patterns = [
            r'([^.!?]+[.!?])',  # ë§ˆì¹¨í‘œ, ëŠë‚Œí‘œ, ë¬¼ìŒí‘œë¡œ ëë‚˜ëŠ” ë¬¸ì¥
            r'([^ê·¸ë¦¬ê³ ]+ê·¸ë¦¬ê³ [^ê·¸ë¦¬ê³ ]+)',  # ê·¸ë¦¬ê³ ë¡œ ì—°ê²°ëœ ì ˆ
            r'([^ë˜ëŠ”]+ë˜ëŠ”[^ë˜ëŠ”]+)',  # ë˜ëŠ”ë¡œ ì—°ê²°ëœ ì ˆ
            r'([^ì´ê³ ]+ì´ê³ [^ì´ê³ ]+)',  # ì´ê³ ë¡œ ì—°ê²°ëœ ì ˆ
            r'([^ì´ê±°ë‚˜]+ì´ê±°ë‚˜[^ì´ê±°ë‚˜]+)',  # ì´ê±°ë‚˜ë¡œ ì—°ê²°ëœ ì ˆ
            r'([^í•˜ë©°]+í•˜ë©°[^í•˜ë©°]+)',  # ë©°ë¡œ ì—°ê²°ëœ ì ˆ
        ]
        
        # 2ë‹¨ê³„: ë³´ì¡° êµ¬ë¶„ìë¡œ ë¶„ë¦¬ (ìš°ì„ ìˆœìœ„ ë‚®ìŒ)
        secondary_patterns = [
            r'([^,]+)',  # ì‰¼í‘œë¡œ êµ¬ë¶„
        ]
        
        # ìš°ì„ ìˆœìœ„ ë†’ì€ íŒ¨í„´ë¶€í„° ì²˜ë¦¬
        for pattern in primary_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                clause_text = match.strip()
                if len(clause_text) > 3 and clause_text not in processed_clauses:
                    clause_info = self._analyze_clause(clause_text)
                    if clause_info:
                        clauses.append(clause_info)
                        processed_clauses.add(clause_text)
        
        # ë§Œì•½ ì ˆì´ ì¶”ì¶œë˜ì§€ ì•Šì•˜ë‹¤ë©´, ìˆ˜ë™ìœ¼ë¡œ ë³µí•©ë¬¸ ë¶„ë¦¬ ì‹œë„
        if not clauses:
            clauses = self._manual_clause_split(text.strip())
        
        return clauses
    
    def _manual_clause_split(self, text: str) -> List[Dict]:
        """ìˆ˜ë™ ì ˆ ë¶„ë¦¬ (ë³µí•©ë¬¸ ì²˜ë¦¬)"""
        clauses = []
        
        # í•œêµ­ì–´ ì—°ê²°ì–´ íŒ¨í„´
        connectors = [
            'ê·¸ë¦¬ê³ ', 'ë˜ëŠ”', 'ì´ê±°ë‚˜', 'ì´ê³ ', 'í•˜ë©°', 'ë©´ì„œ', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ°ë°',
            'ë˜í•œ', 'ë˜í•œ', 'ë˜í•œ', 'ë˜í•œ', 'ë˜í•œ', 'ë˜í•œ', 'ë˜í•œ', 'ë˜í•œ'
        ]
        
        # ì—°ê²°ì–´ë¡œ ë¶„ë¦¬
        parts = [text]
        for connector in connectors:
            new_parts = []
            for part in parts:
                if connector in part:
                    split_parts = part.split(connector)
                    for i, split_part in enumerate(split_parts):
                        if split_part.strip():
                            new_parts.append(split_part.strip())
                        if i < len(split_parts) - 1:  # ë§ˆì§€ë§‰ ë¶€ë¶„ì´ ì•„ë‹ˆë©´ ì—°ê²°ì–´ ì¶”ê°€
                            new_parts.append(connector)
                else:
                    new_parts.append(part)
            parts = new_parts
        
        # ê° ë¶€ë¶„ì„ ì ˆë¡œ ë¶„ì„
        for part in parts:
            if len(part.strip()) > 2:  # ì˜ë¯¸ìˆëŠ” ê¸¸ì´ë§Œ
                clause_info = self._analyze_clause(part.strip())
                if clause_info:
                    clauses.append(clause_info)
        
        return clauses
    
    def _analyze_clause(self, clause: str) -> Optional[Dict]:
        """ì ˆ ë¶„ì„"""
        # jiebaë¡œ í˜•íƒœì†Œ ë¶„ì„
        words = list(jieba.cut(clause))
        
        # ë„ë©”ì¸ ìš©ì–´ í¬í•¨ ì—¬ë¶€ í™•ì¸
        domain_terms = []
        for word in words:
            term_info = self.dict_manager.get_term_info(word)
            if term_info:
                domain_terms.append(term_info)
        
        # ì ˆ ìœ í˜• ë¶„ì„
        clause_type = self._identify_clause_type(clause)
        
        # ì¡°ê±´ë¶€ í‘œí˜„ í™•ì¸
        conditional_type = None
        if "ë§Œì•½" in clause:
            conditional_type = "if_then"
        elif "ì¼ ë•Œ" in clause:
            conditional_type = "when"
        elif "ê·¸ë¦¬ê³ " in clause:
            conditional_type = "and"
        elif "ë˜ëŠ”" in clause:
            conditional_type = "or"
        
        # SQL íŒ¨í„´ í™•ì¸
        sql_patterns = []
        for pattern_type, patterns in self.sql_patterns.items():
            for korean, sql in patterns.items():
                if korean in clause:
                    sql_patterns.append({
                        "korean": korean,
                        "sql": sql,
                        "type": pattern_type
                    })
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence = self._calculate_confidence(clause, domain_terms, sql_patterns)
        
        # í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•œ êµ¬ì¡° ë³€í™˜
        return {
            "type": clause_type,
            "confidence": confidence,
            "content": clause,
            "keywords": [term["term"] for term in domain_terms] if domain_terms else [],
            "clause": clause,
            "words": words,
            "domain_terms": domain_terms,
            "conditional_type": conditional_type,
            "sql_patterns": sql_patterns,
            "length": len(clause)
        }
    
    def _identify_clause_type(self, clause: str) -> str:
        """ì ˆ ìœ í˜• ì‹ë³„"""
        clause_lower = clause.lower()
        
        if "?" in clause or "ëŠ”?" in clause or "ì„?" in clause:
            return "question"
        elif any(word in clause_lower for word in ["í‰ê· ", "í‰ê· ê°’", "avg"]):
            return "aggregation_avg"
        elif any(word in clause_lower for word in ["í•©ê³„", "ì´í•©", "sum"]):
            return "aggregation_sum"
        elif any(word in clause_lower for word in ["ê°œìˆ˜", "ê±´ìˆ˜", "count"]):
            return "aggregation_count"
        elif any(word in clause_lower for word in ["ìµœëŒ€", "ìµœê³ ", "max"]):
            return "aggregation_max"
        elif any(word in clause_lower for word in ["ìµœì†Œ", "ìµœì €", "min"]):
            return "aggregation_min"
        elif any(word in clause_lower for word in ["ì¡°ê±´", "ë§Œì•½", "ì¼ ë•Œ"]):
            return "condition"
        elif any(word in clause_lower for word in ["ê·¸ë¦¬ê³ ", "ë˜ëŠ”", "and", "or"]):
            return "logical"
        else:
            return "general"
    
    def _calculate_confidence(self, clause: str, domain_terms: List, sql_patterns: List) -> float:
        """ì ˆ ë¶„ì„ ì‹ ë¢°ë„ ê³„ì‚°"""
        confidence = 0.5  # ê¸°ë³¸ ì‹ ë¢°ë„
        
        # ë„ë©”ì¸ ìš©ì–´ê°€ ìˆìœ¼ë©´ ì‹ ë¢°ë„ ì¦ê°€
        if domain_terms:
            confidence += 0.2
        
        # SQL íŒ¨í„´ì´ ìˆìœ¼ë©´ ì‹ ë¢°ë„ ì¦ê°€
        if sql_patterns:
            confidence += 0.2
        
        # ì ˆ ê¸¸ì´ê°€ ì ì ˆí•˜ë©´ ì‹ ë¢°ë„ ì¦ê°€
        if 5 <= len(clause) <= 50:
            confidence += 0.1
        
        return min(confidence, 1.0)  # ìµœëŒ€ 1.0
    
    def _generate_reasoning_chain(self, query: str, entities: Dict, clauses: List[Dict]) -> List[str]:
        """Chain of Thought ì¶”ë¡  ìƒì„±"""
        reasoning_steps = []
        
        # 1ë‹¨ê³„: ì§ˆë¬¸ ìœ í˜• íŒŒì•…
        question_type = self._identify_question_type(query)
        reasoning_steps.append(f"ì§ˆë¬¸ ìœ í˜•: {question_type}")
        
        # 2ë‹¨ê³„: ë„ë©”ì¸ ìš©ì–´ ë¶„ì„
        if entities["domain_terms"]:
            terms_summary = ", ".join([term["term"] for term in entities["domain_terms"]])
            reasoning_steps.append(f"ë„ë©”ì¸ ìš©ì–´ ë°œê²¬: {terms_summary}")
        
        # 3ë‹¨ê³„: ì¡°ê±´ ë¶„ì„
        conditions = []
        for clause in clauses:
            if clause["conditional_type"]:
                conditions.append(f"{clause['clause']} ({clause['conditional_type']})")
        
        if conditions:
            reasoning_steps.append(f"ì¡°ê±´ë¶€ í‘œí˜„: {'; '.join(conditions)}")
        
        # 4ë‹¨ê³„: SQL íŒ¨í„´ ë§¤í•‘
        sql_patterns = []
        for clause in clauses:
            for pattern in clause["sql_patterns"]:
                sql_patterns.append(f"{pattern['korean']} â†’ {pattern['sql']}")
        
        if sql_patterns:
            reasoning_steps.append(f"SQL íŒ¨í„´: {'; '.join(sql_patterns)}")
        
        # 5ë‹¨ê³„: ì¶”ë¡  ê²°ê³¼
        reasoning_steps.append("ì¶”ë¡  ì™„ë£Œ: ìì—°ì–´ë¥¼ SQLë¡œ ë³€í™˜í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        return reasoning_steps
    
    def _identify_question_type(self, query: str) -> str:
        """ì§ˆë¬¸ ìœ í˜• íŒŒì•…"""
        query_lower = query.lower()
        
        if any(word in query_lower for word in ["ëª‡", "ê°œìˆ˜", "ê±´ìˆ˜", "ìˆ˜ëŸ‰"]):
            return "COUNT_QUERY"
        elif any(word in query_lower for word in ["í•©ê³„", "ì´í•©", "í•©"]):
            return "SUM_QUERY"
        elif any(word in query_lower for word in ["í‰ê· ", "í‰ê· ê°’"]):
            return "AVG_QUERY"
        elif any(word in query_lower for word in ["ìµœëŒ€", "ìµœê³ "]):
            return "MAX_QUERY"
        elif any(word in query_lower for word in ["ìµœì†Œ", "ìµœì €"]):
            return "MIN_QUERY"
        elif any(word in query_lower for word in ["ëª©ë¡", "ë¦¬ìŠ¤íŠ¸", "ì¡°íšŒ"]):
            return "SELECT_QUERY"
        else:
            return "GENERAL_QUERY"
    
    def _map_sql_patterns(self, text: str) -> Dict:
        """SQL íŒ¨í„´ ë§¤í•‘"""
        mappings = {
            "aggregation": [],
            "comparison": [],
            "ordering": []
        }
        
        for pattern_type, patterns in self.sql_patterns.items():
            for korean, sql in patterns.items():
                if korean in text:
                    mappings[pattern_type].append({
                        "korean": korean,
                        "sql": sql,
                        "context": self._extract_context(text, korean)
                    })
        
        return mappings
    
    def _extract_context(self, text: str, keyword: str) -> str:
        """í‚¤ì›Œë“œ ì£¼ë³€ ë¬¸ë§¥ ì¶”ì¶œ"""
        try:
            index = text.index(keyword)
            start = max(0, index - 20)
            end = min(len(text), index + len(keyword) + 20)
            return text[start:end].strip()
        except ValueError:
            return ""
    
    def _extract_credit_score(self, text: str) -> List[Dict]:
        """ì‹ ìš©ì ìˆ˜ ì¶”ì¶œ"""
        patterns = [
            r'ì‹ ìš©ì ìˆ˜\s*(\d+)',
            r'í¬ë ˆë”§ìŠ¤ì½”ì–´\s*(\d+)',
            r'(\d+)\s*ì '
        ]
        
        scores = []
        for pattern in patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                score = int(match)
                if 300 <= score <= 850:
                    scores.append({
                        "value": score,
                        "type": "credit_score",
                        "range": self._get_score_range(score)
                    })
        
        return scores
    
    def _get_score_range(self, score: int) -> str:
        """ì ìˆ˜ ë²”ìœ„ ë¶„ë¥˜"""
        if score >= 800:
            return "ë§¤ìš°ë†’ìŒ"
        elif score >= 750:
            return "ë†’ìŒ"
        elif score >= 650:
            return "ë³´í†µ"
        elif score >= 550:
            return "ë‚®ìŒ"
        else:
            return "ë§¤ìš°ë‚®ìŒ"
    
    def _extract_risk_level(self, text: str) -> List[str]:
        """ìœ„í—˜ë„ ë ˆë²¨ ì¶”ì¶œ"""
        risk_levels = []
        korean_risk_levels = ["ë§¤ìš°ë‚®ìŒ", "ë‚®ìŒ", "ë³´í†µ", "ë†’ìŒ", "ë§¤ìš°ë†’ìŒ"]
        
        for level in korean_risk_levels:
            if level in text:
                risk_levels.append(level)
        
        return risk_levels
    
    def _extract_loan_amount(self, text: str) -> List[Dict]:
        """ëŒ€ì¶œê¸ˆì•¡ ì¶”ì¶œ"""
        patterns = [
            r'ëŒ€ì¶œê¸ˆì•¡\s*(\d+)ì›',
            r'(\d+)ì›\s*ëŒ€ì¶œ',
            r'ëŒ€ì¶œ\s*(\d+)ì›'
        ]
        
        amounts = []
        for pattern in patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                amounts.append({
                    "value": int(match),
                    "type": "loan_amount",
                    "unit": "ì›"
                })
        
        return amounts
    
    def _extract_customer_type(self, text: str) -> List[str]:
        """ê³ ê° ìœ í˜• ì¶”ì¶œ"""
        customer_types = []
        type_patterns = {
            "ê°œì¸ê³ ê°": ["ê°œì¸", "ê°œì¸ê³ ê°", "ê°œì¸ì‹ ìš©"],
            "ê¸°ì—…ê³ ê°": ["ê¸°ì—…", "ê¸°ì—…ê³ ê°", "ê¸°ì—…ì‹ ìš©"],
            "ì†Œìƒê³µì¸": ["ì†Œìƒê³µì¸", "ì†Œìƒê³µì¸ê³ ê°"],
            "VIPê³ ê°": ["VIP", "VIPê³ ê°", "ìš°ìˆ˜ê³ ê°"],
            "ê´€ë¦¬ê³ ê°": ["ê´€ë¦¬", "ê´€ë¦¬ê³ ê°", "ì£¼ì˜ê³ ê°"]
        }
        
        for customer_type, patterns in type_patterns.items():
            if any(pattern in text for pattern in patterns):
                customer_types.append(customer_type)
        
        return customer_types
    
    def _extract_date_range(self, text: str) -> List[Dict]:
        """ë‚ ì§œ ë²”ìœ„ ì¶”ì¶œ"""
        date_patterns = [
            r'(\d{4})ë…„(\d{1,2})ì›”(\d{1,2})ì¼',
            r'(\d{4})-(\d{1,2})-(\d{1,2})',
            r'(\d{1,2})ì›”(\d{1,2})ì¼'
        ]
        
        dates = []
        for pattern in date_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                if len(match) == 3:
                    dates.append({
                        "year": match[0],
                        "month": match[1],
                        "day": match[2],
                        "type": "full_date"
                    })
                elif len(match) == 2:
                    dates.append({
                        "month": match[0],
                        "day": match[1],
                        "type": "month_day"
                    })
        
        return dates
    
    def _extract_numeric_range(self, text: str) -> List[Dict]:
        """ìˆ«ì ë²”ìœ„ ì¶”ì¶œ"""
        range_patterns = [
            r'(\d+)\s*ì´ìƒ\s*(\d+)ì´í•˜',
            r'(\d+)\s*ë¶€í„°\s*(\d+)ê¹Œì§€',
            r'(\d+)\s*~\s*(\d+)',
            r'(\d+)\s*-\s*(\d+)'
        ]
        
        ranges = []
        for pattern in range_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                ranges.append({
                    "min": int(match[0]),
                    "max": int(match[1]),
                    "type": "numeric_range"
                })
        
        return ranges

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
hybrid_agent = HybridPreprocessingAgent()

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = [
        "ì‹ ìš©ì ìˆ˜ 750 ì´ìƒì¸ ê°œì¸ê³ ê°ì˜ ëŒ€ì¶œê¸ˆì•¡ í•©ê³„ë¥¼ ì¡°íšŒí•´ì£¼ì„¸ìš”",
        "ìœ„í—˜ë„ê°€ ë†’ì€ ê¸°ì—…ê³ ê° ì¤‘ ì—°ì²´ì¼ìˆ˜ê°€ 30ì¼ ì´ìƒì¸ ê³ ê° ìˆ˜ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”",
        "VIPê³ ê°ì˜ í‰ê·  ì‹ ìš©ì ìˆ˜ì™€ ì¼ë°˜ê³ ê°ì˜ í‰ê·  ì‹ ìš©ì ìˆ˜ë¥¼ ë¹„êµí•´ì£¼ì„¸ìš”",
        "ì†Œë“ìˆ˜ì¤€ì´ ë³´í†µì´ê³  ì‹ ìš©ì ìˆ˜ê°€ 650 ì´ìƒì¸ ê³ ê° ëª©ë¡ì„ ì¡°íšŒí•´ì£¼ì„¸ìš”"
    ]
    
    print("ğŸ”§ ê·œì¹™ ê¸°ë°˜ + ë”•ì…”ë„ˆë¦¬ í˜¼í•© ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸\n")
    
    for i, query in enumerate(test_queries, 1):
        print(f"ğŸ“ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ {i}: {query}")
        result = hybrid_agent.preprocess_query(query)
        
        if "error" not in result:
            print(f"âœ… ì •ê·œí™”ëœ ì¿¼ë¦¬: {result['normalized_query']}")
            print(f"ğŸ”— ë§¤í•‘ëœ ì¿¼ë¦¬: {result['mapped_query']}")
            print(f"ğŸ·ï¸ ë„ë©”ì¸ ìš©ì–´: {len(result['entities']['domain_terms'])}ê°œ")
            print(f"ğŸ“‹ ì ˆ(Clause): {len(result['clauses'])}ê°œ")
            print(f"ğŸ§  ì¶”ë¡  ë‹¨ê³„: {len(result['reasoning_chain'])}ë‹¨ê³„")
            print(f"ğŸ”§ SQL íŒ¨í„´: {len(result['sql_mappings']['aggregation'] + result['sql_mappings']['comparison'] + result['sql_mappings']['ordering'])}ê°œ")
            print()
        else:
            print(f"âŒ ì˜¤ë¥˜: {result['error']}")
            print() 