from flask import Flask, request, jsonify
from flask_cors import CORS
import os
from datetime import datetime
import openai
import requests
import glob
import pandas as pd
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()
try:
    from openai import OpenAI
    openai_client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
except ImportError:
    openai_client = None  # êµ¬ë²„ì „ í˜¸í™˜
from werkzeug.utils import secure_filename

# ì„¤ì • ë° ìœ í‹¸ë¦¬í‹° import
from config.config import config
from utils.utils import (
    allowed_file, get_file_info, generate_sample_data, parse_user_metadata,
    call_local_llm, convert_question_to_sql_rule_based, create_directories
)

# RAG ì„œë¹„ìŠ¤ import
from services.rag_service import get_rag_service

# í•œêµ­ì–´ ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸ import (hybrid ë°©ì‹ ì‚¬ìš©)
try:
    from preprocessing.hybrid_preprocessing_agent import hybrid_agent
    korean_preprocessing_agent = hybrid_agent
    KOREAN_PREPROCESSING_AVAILABLE = True
    print("âœ… í•œêµ­ì–´ ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸(í˜¼í•© ë°©ì‹) ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    print(f"âŒ í•œêµ­ì–´ ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    korean_preprocessing_agent = None
    KOREAN_PREPROCESSING_AVAILABLE = False



# ë™ì  ë”•ì…”ë„ˆë¦¬ ê´€ë¦¬ì import
try:
    from services.dynamic_dictionary_manager import dictionary_manager
    DICTIONARY_MANAGER_AVAILABLE = True
    print("âœ… ë™ì  ë”•ì…”ë„ˆë¦¬ ê´€ë¦¬ì ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    print(f"âŒ ë™ì  ë”•ì…”ë„ˆë¦¬ ê´€ë¦¬ì ë¡œë“œ ì‹¤íŒ¨: {e}")
    dictionary_manager = None
    DICTIONARY_MANAGER_AVAILABLE = False


app = Flask(__name__)
CORS(app)

# LLM ì„¤ì •
LLM_PROVIDER = os.getenv('LLM_PROVIDER', 'openai')
LLM_BASE_URL = os.getenv('LLM_BASE_URL')
LLM_API_KEY = os.getenv('LLM_API_KEY')
LLM_MODEL = os.getenv('LLM_MODEL', 'gpt-3.5-turbo')

# OpenAI API ì„¤ì • (ê¸°ë³¸ê°’)
# openai.api_key = os.getenv('OPENAI_API_KEY') # ì´ì œ openai_client ì‚¬ìš©
OPENAI_MODEL = os.getenv('OPENAI_MODEL', 'gpt-3.5-turbo')

# RAG íŒŒì¼ ì—…ë¡œë“œ ì„¤ì •
UPLOAD_FOLDER = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data', 'rag_files')
ALLOWED_EXTENSIONS = {'txt', 'pdf', 'docx', 'doc', 'csv', 'json', 'md'}

# ë„ë©”ì¸ë³„ í´ë” êµ¬ì¡°
RAG_DOMAINS = {
    'personal_credit': 'ê°œì¸ ì‹ ìš©ì •ë³´',
    'corporate_credit': 'ê¸°ì—… ì‹ ìš©ì •ë³´',
    'policy_regulation': 'í‰ê°€ ì •ì±… ë° ê·œì œ'
}

# ì—…ë¡œë“œ í´ë” ìƒì„±
for domain in RAG_DOMAINS.keys():
    domain_path = os.path.join(UPLOAD_FOLDER, domain)
    os.makedirs(domain_path, exist_ok=True)

# ì‚¬ìš©ì ì—…ë¡œë“œ ë©”íƒ€ë°ì´í„° ì €ì¥ ê²½ë¡œ
USER_METADATA_DIR = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data', 'metadata')
ACTIVE_META_FILE = os.path.join(USER_METADATA_DIR, 'active.txt')

# í´ë” ìƒì„± ë³´ì¥
os.makedirs(USER_METADATA_DIR, exist_ok=True)

def allowed_file(filename):
    """í—ˆìš©ëœ íŒŒì¼ í™•ì¥ìì¸ì§€ í™•ì¸"""
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def get_file_info(filepath):
    """íŒŒì¼ ì •ë³´ë¥¼ ë°˜í™˜"""
    stat = os.stat(filepath)
    return {
        'filename': os.path.basename(filepath),
        'size': stat.st_size,
        'upload_date': datetime.fromtimestamp(stat.st_mtime).isoformat(),
        'path': filepath
    }

# ê³ ê° ë©”íƒ€ë°ì´í„° (ì‹ ìš©í‰ê°€ìš©)
CUSTOMER_METADATA = {
    "tables": {
        "customers": {
            "description": "ê³ ê° ê¸°ë³¸ ì •ë³´ í…Œì´ë¸”",
            "columns": {
                "customer_id": {"type": "INTEGER", "description": "ê³ ê° ê³ ìœ  ID"},
                "name": {"type": "VARCHAR(100)", "description": "ê³ ê° ì´ë¦„"},
                "age": {"type": "INTEGER", "description": "ê³ ê° ë‚˜ì´"},
                "gender": {"type": "VARCHAR(10)", "description": "ì„±ë³„ (M/F)"},
                "email": {"type": "VARCHAR(100)", "description": "ì´ë©”ì¼ ì£¼ì†Œ"},
                "phone": {"type": "VARCHAR(20)", "description": "ì „í™”ë²ˆí˜¸"},
                "address": {"type": "TEXT", "description": "ì£¼ì†Œ"},
                "registration_date": {"type": "DATE", "description": "ê°€ì…ì¼"},
                "occupation": {"type": "VARCHAR(50)", "description": "ì§ì—…"},
                "income_level": {"type": "VARCHAR(20)", "description": "ì†Œë“ ìˆ˜ì¤€ (LOW/MEDIUM/HIGH)"}
            }
        },
        "credit_scores": {
            "description": "ê³ ê° ì‹ ìš©ì ìˆ˜ ì •ë³´",
            "columns": {
                "customer_id": {"type": "INTEGER", "description": "ê³ ê° ê³ ìœ  ID (customers í…Œì´ë¸” ì°¸ì¡°)"},
                "credit_score": {"type": "INTEGER", "description": "ì‹ ìš©ì ìˆ˜ (300-850)"},
                "score_date": {"type": "DATE", "description": "ì ìˆ˜ í‰ê°€ì¼"},
                "credit_bureau": {"type": "VARCHAR(50)", "description": "ì‹ ìš©í‰ê°€ê¸°ê´€"},
                "risk_level": {"type": "VARCHAR(20)", "description": "ìœ„í—˜ë„ (LOW/MEDIUM/HIGH)"}
            }
        },
        "loan_history": {
            "description": "ëŒ€ì¶œ ì´ë ¥ ì •ë³´",
            "columns": {
                "loan_id": {"type": "INTEGER", "description": "ëŒ€ì¶œ ê³ ìœ  ID"},
                "customer_id": {"type": "INTEGER", "description": "ê³ ê° ê³ ìœ  ID (customers í…Œì´ë¸” ì°¸ì¡°)"},
                "loan_amount": {"type": "DECIMAL(15,2)", "description": "ëŒ€ì¶œ ê¸ˆì•¡"},
                "loan_type": {"type": "VARCHAR(50)", "description": "ëŒ€ì¶œ ìœ í˜• (MORTGAGE/PERSONAL/BUSINESS)"},
                "interest_rate": {"type": "DECIMAL(5,2)", "description": "ì´ììœ¨ (%)"},
                "loan_date": {"type": "DATE", "description": "ëŒ€ì¶œ ì‹œì‘ì¼"},
                "due_date": {"type": "DATE", "description": "ë§Œê¸°ì¼"},
                "status": {"type": "VARCHAR(20)", "description": "ìƒíƒœ (ACTIVE/PAID/DEFAULTED)"},
                "monthly_payment": {"type": "DECIMAL(10,2)", "description": "ì›” ìƒí™˜ì•¡"}
            }
        },
        "payment_history": {
            "description": "ê²°ì œ ì´ë ¥ ì •ë³´",
            "columns": {
                "payment_id": {"type": "INTEGER", "description": "ê²°ì œ ê³ ìœ  ID"},
                "loan_id": {"type": "INTEGER", "description": "ëŒ€ì¶œ ID (loan_history í…Œì´ë¸” ì°¸ì¡°)"},
                "payment_date": {"type": "DATE", "description": "ê²°ì œì¼"},
                "payment_amount": {"type": "DECIMAL(10,2)", "description": "ê²°ì œ ê¸ˆì•¡"},
                "payment_type": {"type": "VARCHAR(20)", "description": "ê²°ì œ ìœ í˜• (ON_TIME/LATE/DEFAULT)"},
                "days_late": {"type": "INTEGER", "description": "ì—°ì²´ ì¼ìˆ˜"}
            }
        },
        "employment_history": {
            "description": "ê³ ìš© ì´ë ¥ ì •ë³´",
            "columns": {
                "employment_id": {"type": "INTEGER", "description": "ê³ ìš© ì´ë ¥ ID"},
                "customer_id": {"type": "INTEGER", "description": "ê³ ê° ê³ ìœ  ID (customers í…Œì´ë¸” ì°¸ì¡°)"},
                "company_name": {"type": "VARCHAR(100)", "description": "íšŒì‚¬ëª…"},
                "position": {"type": "VARCHAR(50)", "description": "ì§ì±…"},
                "start_date": {"type": "DATE", "description": "ì…ì‚¬ì¼"},
                "end_date": {"type": "DATE", "description": "í‡´ì‚¬ì¼ (NULLì´ë©´ ì¬ì§ì¤‘)"},
                "salary": {"type": "DECIMAL(12,2)", "description": "ì—°ë´‰"},
                "employment_type": {"type": "VARCHAR(20)", "description": "ê³ ìš© í˜•íƒœ (FULL_TIME/PART_TIME/CONTRACT)"}
            }
        }
    }
}

# ìƒ˜í”Œ ë°ì´í„° ìƒì„±
def generate_sample_data():
    sample_data = {
        "customers": [
            {"customer_id": 1, "name": "ê¹€ì² ìˆ˜", "age": 35, "gender": "M", "email": "kim@email.com", "phone": "010-1234-5678", "address": "ì„œìš¸ì‹œ ê°•ë‚¨êµ¬", "registration_date": "2020-01-15", "occupation": "ì—”ì§€ë‹ˆì–´", "income_level": "HIGH"},
            {"customer_id": 2, "name": "ì´ì˜í¬", "age": 28, "gender": "F", "email": "lee@email.com", "phone": "010-2345-6789", "address": "ì„œìš¸ì‹œ ì„œì´ˆêµ¬", "registration_date": "2019-06-20", "occupation": "ë””ìì´ë„ˆ", "income_level": "MEDIUM"},
            {"customer_id": 3, "name": "ë°•ë¯¼ìˆ˜", "age": 42, "gender": "M", "email": "park@email.com", "phone": "010-3456-7890", "address": "ë¶€ì‚°ì‹œ í•´ìš´ëŒ€êµ¬", "registration_date": "2018-11-10", "occupation": "ë§¤ë‹ˆì €", "income_level": "HIGH"},
            {"customer_id": 4, "name": "ìµœì§€ì˜", "age": 31, "gender": "F", "email": "choi@email.com", "phone": "010-4567-8901", "address": "ëŒ€êµ¬ì‹œ ìˆ˜ì„±êµ¬", "registration_date": "2021-03-05", "occupation": "êµì‚¬", "income_level": "MEDIUM"},
            {"customer_id": 5, "name": "ì •í˜„ìš°", "age": 39, "gender": "M", "email": "jung@email.com", "phone": "010-5678-9012", "address": "ì¸ì²œì‹œ ì—°ìˆ˜êµ¬", "registration_date": "2017-09-12", "occupation": "ì˜ì‚¬", "income_level": "HIGH"}
        ],
        "credit_scores": [
            {"customer_id": 1, "credit_score": 750, "score_date": "2023-12-01", "credit_bureau": "NICE", "risk_level": "LOW"},
            {"customer_id": 2, "credit_score": 680, "score_date": "2023-12-01", "credit_bureau": "NICE", "risk_level": "MEDIUM"},
            {"customer_id": 3, "credit_score": 720, "score_date": "2023-12-01", "credit_bureau": "NICE", "risk_level": "LOW"},
            {"customer_id": 4, "credit_score": 620, "score_date": "2023-12-01", "credit_bureau": "NICE", "risk_level": "MEDIUM"},
            {"customer_id": 5, "credit_score": 800, "score_date": "2023-12-01", "credit_bureau": "NICE", "risk_level": "LOW"}
        ]
    }
    return sample_data

# ì—‘ì…€ ë©”íƒ€ë°ì´í„° íŒŒì‹± í•¨ìˆ˜

def parse_user_metadata():
    """ì—…ë¡œë“œëœ ì—‘ì…€ íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ë©”íƒ€ë°ì´í„° dictë¡œ ë³€í™˜"""
    if not os.path.exists(ACTIVE_META_FILE):
        return None
    try:
        with open(ACTIVE_META_FILE, 'r', encoding='utf-8') as f:
            filename = f.read().strip()
        path = os.path.join(USER_METADATA_DIR, filename)
        if not os.path.exists(path):
            return None
        df = pd.read_excel(path)
        # ê¸°ëŒ€ í¬ë§·: í…Œì´ë¸”ëª…, ì»¬ëŸ¼ëª…, íƒ€ì…, ì„¤ëª…
        meta = {"tables": {}}
        for _, row in df.iterrows():
            table = str(row["í…Œì´ë¸”ëª…"]).strip()
            col = str(row["ì»¬ëŸ¼ëª…"]).strip()
            typ = str(row["íƒ€ì…"]).strip()
            desc = str(row["ì„¤ëª…"]).strip() if "ì„¤ëª…" in row else ""
            if table not in meta["tables"]:
                meta["tables"][table] = {"description": "", "columns": {}}
            meta["tables"][table]["columns"][col] = {"type": typ, "description": desc}
        return meta
    except Exception as e:
        print(f"ì—‘ì…€ ë©”íƒ€ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜: {e}")
        return None

# get_metadata ì—”ë“œí¬ì¸íŠ¸ ìˆ˜ì •: ì‚¬ìš©ì ë©”íƒ€ë°ì´í„° ìš°ì„  ë°˜í™˜
@app.route('/api/metadata', methods=['GET'])
def get_metadata():
    """ë°ì´í„°ë² ì´ìŠ¤ ë©”íƒ€ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. (ì‚¬ìš©ì ì—…ë¡œë“œ ìš°ì„ )"""
    try:
        user_meta = parse_user_metadata()
        if user_meta:
            print(f"ì‚¬ìš©ì ë©”íƒ€ë°ì´í„° ë°˜í™˜: {len(user_meta.get('tables', {}))}ê°œ í…Œì´ë¸”")
            return jsonify(user_meta)
        else:
            print("ê¸°ë³¸ ë©”íƒ€ë°ì´í„° ë°˜í™˜")
            return jsonify(CUSTOMER_METADATA)
    except Exception as e:
        print(f"ë©”íƒ€ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify(CUSTOMER_METADATA)

@app.route('/api/sample-data', methods=['GET'])
def get_sample_data():
    """ìƒ˜í”Œ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return jsonify(generate_sample_data())

# ì—…ë¡œë“œ ì‹œ íŒŒì¼ëª… ì¤‘ë³µ ë°©ì§€ ë° ì €ì¥
@app.route('/api/metadata/upload', methods=['POST'])
def upload_metadata():
    if 'file' not in request.files:
        return jsonify({"error": "íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."}), 400
    file = request.files['file']
    if file.filename == '' or not file.filename.lower().endswith('.xlsx'):
        return jsonify({"error": "ì—‘ì…€(xlsx) íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."}), 400
    try:
        # íŒŒì¼ëª… ì¤‘ë³µ ë°©ì§€(íƒ€ì„ìŠ¤íƒ¬í”„)
        base = os.path.splitext(secure_filename(file.filename))[0]
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        save_name = f"{base}_{timestamp}.xlsx"
        save_path = os.path.join(USER_METADATA_DIR, save_name)
        file.save(save_path)
        print(f"ë©”íƒ€ë°ì´í„° íŒŒì¼ ì €ì¥ë¨: {save_path}")
        
        # ì—…ë¡œë“œ ì‹œ ìë™ ì ìš©
        with open(ACTIVE_META_FILE, 'w', encoding='utf-8') as f:
            f.write(save_name)
        print(f"í™œì„± ë©”íƒ€ë°ì´í„° íŒŒì¼ ì„¤ì •ë¨: {save_name}")
        
        # íŒŒì‹± í…ŒìŠ¤íŠ¸
        parsed_meta = parse_user_metadata()
        if parsed_meta:
            print(f"ë©”íƒ€ë°ì´í„° íŒŒì‹± ì„±ê³µ: {len(parsed_meta.get('tables', {}))}ê°œ í…Œì´ë¸”")
        else:
            print("ë©”íƒ€ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨")
            
        return jsonify({"message": "ë©”íƒ€ë°ì´í„° íŒŒì¼ì´ ì—…ë¡œë“œ ë° ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.", "filename": save_name})
    except Exception as e:
        print(f"ë©”íƒ€ë°ì´í„° ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
        return jsonify({"error": str(e)}), 500

# ë©”íƒ€ë°ì´í„° íŒŒì¼ ëª©ë¡ ì¡°íšŒ
@app.route('/api/metadata/list', methods=['GET'])
def list_metadata():
    files = []
    for path in glob.glob(os.path.join(USER_METADATA_DIR, '*.xlsx')):
        stat = os.stat(path)
        files.append({
            'filename': os.path.basename(path),
            'size': stat.st_size,
            'upload_date': datetime.fromtimestamp(stat.st_mtime).isoformat()
        })
    # í˜„ì¬ ì ìš©ì¤‘ì¸ íŒŒì¼
    active = None
    if os.path.exists(ACTIVE_META_FILE):
        with open(ACTIVE_META_FILE, 'r', encoding='utf-8') as f:
            active = f.read().strip()
    return jsonify({'files': files, 'active': active})

# ë©”íƒ€ë°ì´í„° íŒŒì¼ ì ìš©
@app.route('/api/metadata/apply', methods=['POST'])
def apply_metadata():
    data = request.get_json()
    filename = data.get('filename')
    path = os.path.join(USER_METADATA_DIR, filename)
    if not os.path.exists(path):
        return jsonify({"error": "íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."}), 404
    with open(ACTIVE_META_FILE, 'w', encoding='utf-8') as f:
        f.write(filename)
    return jsonify({"message": "ì ìš© ì™„ë£Œ", "filename": filename})

# ë©”íƒ€ë°ì´í„° íŒŒì¼ ì‚­ì œ
@app.route('/api/metadata/delete/<filename>', methods=['DELETE'])
def delete_metadata(filename):
    path = os.path.join(USER_METADATA_DIR, filename)
    if not os.path.exists(path):
        return jsonify({"error": "íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."}), 404
    try:
        os.remove(path)
        # ì‚­ì œí•œ íŒŒì¼ì´ activeë©´ active í•´ì œ
        if os.path.exists(ACTIVE_META_FILE):
            with open(ACTIVE_META_FILE, 'r', encoding='utf-8') as f:
                active = f.read().strip()
            if active == filename:
                os.remove(ACTIVE_META_FILE)
        return jsonify({"message": "ì‚­ì œ ì™„ë£Œ"})
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# convert_question_to_sqlì—ì„œ ë©”íƒ€ë°ì´í„°ë¥¼ ë™ì ìœ¼ë¡œ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •
@app.route('/api/convert', methods=['POST'])
def convert_to_sql():
    """ìì—°ì–´ ì§ˆë¬¸ì„ SQLë¡œ ë³€í™˜í•©ë‹ˆë‹¤. (RAG ë¬¸ì„œ, ì‚¬ìš©ì ë©”íƒ€ë°ì´í„° í™œìš©)"""
    try:
        data = request.get_json()
        question = data.get('question', '')
        rag_domain = data.get('rag_domain', None)
        if not question:
            return jsonify({"error": "ì§ˆë¬¸ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        # ìƒˆë¡œìš´ RAG ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        rag_context = rag_service.get_rag_context(question, rag_domain, top_k=5)
        
        # ë©”íƒ€ë°ì´í„° ë™ì  ë¡œë”©
        user_meta = parse_user_metadata()
        meta = user_meta if user_meta else CUSTOMER_METADATA
        sql_query = convert_question_to_sql(question, rag_context, meta)
        
        # ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸ ì •ë³´ ì¶”ê°€ (í˜¼í•© ë°©ì‹ ìš°ì„ )
        preprocessing_info = {}
        
        # í˜¼í•© ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸ ì‚¬ìš© (ìš°ì„ )
        if KOREAN_PREPROCESSING_AVAILABLE and korean_preprocessing_agent:
            try:
                preprocessed = korean_preprocessing_agent.preprocess_query(question)
                preprocessing_info = {
                    "agent_type": "hybrid",
                    "available": True,
                    "original_query": preprocessed["original_query"],
                    "normalized_query": preprocessed["normalized_query"],
                    "mapped_query": preprocessed["mapped_query"],
                    "entities": preprocessed["entities"],
                    "clauses": preprocessed["clauses"],
                    "reasoning_chain": preprocessed["reasoning_chain"],
                    "sql_mappings": preprocessed["sql_mappings"],
                    "preprocessing_metadata": preprocessed["preprocessing_metadata"],
                    "domain_terms_found": preprocessed["preprocessing_metadata"]["domain_terms_found"],
                    "clauses_count": preprocessed["preprocessing_metadata"]["clauses_count"],
                    "reasoning_steps": preprocessed["preprocessing_metadata"]["reasoning_steps"],
                    "sql_patterns_mapped": preprocessed["preprocessing_metadata"]["sql_patterns_mapped"]
                }
                print(f"ğŸ”§ í˜¼í•© ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸ ì‚¬ìš© - ë„ë©”ì¸ ìš©ì–´: {preprocessed['preprocessing_metadata']['domain_terms_found']}ê°œ")
                print(f"ğŸ“‹ ì ˆ(Clause): {preprocessed['preprocessing_metadata']['clauses_count']}ê°œ")
                
            except Exception as e:
                preprocessing_info = {
                    "agent_type": "hybrid",
                    "available": True,
                    "error": str(e)
                }
        
        # ê¸°ì¡´ í•œêµ­ì–´ ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸ ì‚¬ìš© (fallback)
        elif KOREAN_PREPROCESSING_AVAILABLE and korean_preprocessing_agent:
            try:
                preprocessed = korean_preprocessing_agent.preprocess_query(question)
                preprocessing_info = {
                    "agent_type": "korean",
                    "available": True,
                    "clauses_count": len(preprocessed.clauses),
                    "sql_keywords": preprocessed.sql_keywords,
                    "entities_count": len(preprocessed.entities),
                    "normalized_query": preprocessed.normalized_query,
                    "clause_types": korean_preprocessing_agent.get_clause_summary(preprocessed)["clause_types"]
                }
            except Exception as e:
                preprocessing_info = {
                    "agent_type": "korean",
                    "available": True,
                    "error": str(e)
                }
        else:
            preprocessing_info = {
                "agent_type": "none",
                "available": False,
                "reason": "ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }
        
        return jsonify({
            "question": question,
            "sql": sql_query,
            "timestamp": datetime.now().isoformat(),
            "rag_context_used": bool(rag_context),  # RAG ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš© ì—¬ë¶€
            "preprocessing": preprocessing_info
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
rag_service = get_rag_service()

# ê¸°ì¡´ ë¬¸ì„œë“¤ì„ ë²¡í„° DBì— ì²˜ë¦¬ (ìµœì´ˆ 1íšŒë§Œ ì‹¤í–‰)
def initialize_rag_database():
    """ê¸°ì¡´ RAG ë¬¸ì„œë“¤ì„ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì²˜ë¦¬"""
    try:
        # ê¸°ì¡´ ë¬¸ì„œ ì²˜ë¦¬
        results = rag_service.process_all_existing_documents()
        print(f"RAG ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ: {len(results)}ê°œ ë¬¸ì„œ ì²˜ë¦¬ë¨")
        return results
    except Exception as e:
        print(f"RAG ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return []

# ì•± ì‹œì‘ ì‹œ RAG DB ì´ˆê¸°í™” (ìˆ˜ë™ìœ¼ë¡œ ì‹¤í–‰í•˜ë ¤ë©´ ì£¼ì„ ì²˜ë¦¬)
# initialize_rag_database()

# convert_question_to_sql í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ ë° ë‚´ë¶€ ìˆ˜ì •

def call_local_llm(prompt, system_prompt="ë‹¹ì‹ ì€ ìì—°ì–´ë¥¼ SQLë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."):
    """ë¡œì»¬ LLM API í˜¸ì¶œ í•¨ìˆ˜"""
    try:
        headers = {
            'Content-Type': 'application/json'
        }
        
        if LLM_API_KEY:
            headers['Authorization'] = f'Bearer {LLM_API_KEY}'
        
        payload = {
            "model": LLM_MODEL,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            "max_tokens": 500,
            "temperature": 0.1
        }
        
        response = requests.post(
            f"{LLM_BASE_URL}/v1/chat/completions",
            headers=headers,
            json=payload,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            return result['choices'][0]['message']['content'].strip()
        else:
            print(f"ë¡œì»¬ LLM API ì˜¤ë¥˜: {response.status_code} - {response.text}")
            return None
            
    except Exception as e:
        print(f"ë¡œì»¬ LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def convert_question_to_sql(question, rag_context=None, meta=None):
    """ìì—°ì–´ ì§ˆë¬¸ì„ SQLë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ (í•œêµ­ì–´ ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸ + RAG context + ë™ì  ë©”íƒ€ë°ì´í„° í™œìš©)"""
    
    # í•œêµ­ì–´ ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸ ì‚¬ìš© (ê°€ëŠ¥í•œ ê²½ìš°)
    enhanced_prompt = None
    preprocessing_info = {}
    
    if KOREAN_PREPROCESSING_AVAILABLE and korean_preprocessing_agent:
        try:
            # ì „ì²˜ë¦¬ ìˆ˜í–‰
            preprocessed = korean_preprocessing_agent.preprocess_query(question)
            
            # í–¥ìƒëœ í”„ë¡¬í”„íŠ¸ ìƒì„±
            enhanced_prompt = korean_preprocessing_agent.generate_enhanced_prompt(preprocessed)
            
            # ì „ì²˜ë¦¬ ì •ë³´ ì €ì¥
            preprocessing_info = {
                "clauses_count": len(preprocessed.clauses),
                "sql_keywords": preprocessed.sql_keywords,
                "entities_count": len(preprocessed.entities),
                "normalized_query": preprocessed.normalized_query
            }
            
            print(f"ğŸ‡°ğŸ‡· í•œêµ­ì–´ ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸ ì‚¬ìš© - ì¶”ì¶œëœ ì ˆ: {len(preprocessed.clauses)}ê°œ")
            print(f"ğŸ”‘ SQL í‚¤ì›Œë“œ: {preprocessed.sql_keywords}")
            
        except Exception as e:
            print(f"âŒ í•œêµ­ì–´ ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸ ì˜¤ë¥˜: {e}")
            enhanced_prompt = None
    
    # ë¡œì»¬ LLM ì‚¬ìš© ì‹œ
    if LLM_PROVIDER in ['ollama', 'enterprise'] and LLM_BASE_URL:
        try:
            # ë©”íƒ€ë°ì´í„°ë¥¼ í”„ë¡¬í”„íŠ¸ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            if meta is None:
                meta = CUSTOMER_METADATA
            schema_info = "ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ:\n"
            for tname, tinfo in meta["tables"].items():
                schema_info += f"- {tname} í…Œì´ë¸”: "
                schema_info += ", ".join([f"{col}({cinfo['type']})" for col, cinfo in tinfo["columns"].items()]) + "\n"
            
            # ì „ì²˜ë¦¬ëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš© ë˜ëŠ” ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            if enhanced_prompt:
                prompt = f"{schema_info}\n{enhanced_prompt}"
            else:
                prompt = f"{schema_info}\n"
                if rag_context:
                    prompt += f"[ì°¸ê³  ë¬¸ì„œ]\n{rag_context}\n"
                prompt += (
                    f"ë‹¤ìŒ ìì—°ì–´ ì§ˆë¬¸ì„ SQL ì¿¼ë¦¬ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.\n"
                    f"ì§ˆë¬¸: {question}\n\n"
                    "ìš”êµ¬ì‚¬í•­:\n"
                    "1. SQLë§Œ ì¶œë ¥í•˜ê³  ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”\n"
                    "2. ì ì ˆí•œ JOINì„ ì‚¬ìš©í•˜ì„¸ìš”\n"
                    "3. WHERE ì¡°ê±´ì„ ëª…í™•íˆ í•˜ì„¸ìš”\n"
                    "4. ORDER BY, GROUP BY, LIMIT ë“±ì„ ì ì ˆíˆ ì‚¬ìš©í•˜ì„¸ìš”\n"
                    "5. ì»¬ëŸ¼ëª…ì€ ì •í™•íˆ ì‚¬ìš©í•˜ì„¸ìš”\n"
                )
            
            sql_query = call_local_llm(prompt)
            if sql_query and any(keyword in sql_query.upper() for keyword in ['SELECT', 'FROM', 'WHERE', 'JOIN']):
                return sql_query
            else:
                return convert_question_to_sql_rule_based(question)
                
        except Exception as e:
            print(f"ë¡œì»¬ LLM ë³€í™˜ ì˜¤ë¥˜: {e}")
            return convert_question_to_sql_rule_based(question)
    
    # OpenAI API ì‚¬ìš© ì‹œ
    if not os.getenv('OPENAI_API_KEY') or not openai_client:
        return convert_question_to_sql_rule_based(question)
    try:
        # ë©”íƒ€ë°ì´í„°ë¥¼ í”„ë¡¬í”„íŠ¸ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        if meta is None:
            meta = CUSTOMER_METADATA
        schema_info = "ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ:\n"
        for tname, tinfo in meta["tables"].items():
            schema_info += f"- {tname} í…Œì´ë¸”: "
            schema_info += ", ".join([f"{col}({cinfo['type']})" for col, cinfo in tinfo["columns"].items()]) + "\n"
        
        # ì „ì²˜ë¦¬ëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš© ë˜ëŠ” ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        if enhanced_prompt:
            prompt = f"{schema_info}\n{enhanced_prompt}"
        else:
            prompt = f"{schema_info}\n"
            if rag_context:
                prompt += f"[ì°¸ê³  ë¬¸ì„œ]\n{rag_context}\n"
            prompt += (
                f"ë‹¤ìŒ ìì—°ì–´ ì§ˆë¬¸ì„ SQL ì¿¼ë¦¬ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.\n"
                f"ì§ˆë¬¸: {question}\n\n"
                "ìš”êµ¬ì‚¬í•­:\n"
                "1. SQLë§Œ ì¶œë ¥í•˜ê³  ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”\n"
                "2. ì ì ˆí•œ JOINì„ ì‚¬ìš©í•˜ì„¸ìš”\n"
                "3. WHERE ì¡°ê±´ì„ ëª…í™•íˆ í•˜ì„¸ìš”\n"
                "4. ORDER BY, GROUP BY, LIMIT ë“±ì„ ì ì ˆíˆ ì‚¬ìš©í•˜ì„¸ìš”\n"
                "5. ì»¬ëŸ¼ëª…ì€ ì •í™•íˆ ì‚¬ìš©í•˜ì„¸ìš”\n"
            )
        
        response = openai_client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ìì—°ì–´ë¥¼ SQLë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆì™€ ì°¸ê³  ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•œ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=500,
            temperature=0.1
        )
        sql_query = response.choices[0].message.content.strip()
        if any(keyword in sql_query.upper() for keyword in ['SELECT', 'FROM', 'WHERE', 'JOIN']):
            return sql_query
        else:
            return convert_question_to_sql_rule_based(question)
    except Exception as e:
        print(f"OpenAI API ì˜¤ë¥˜: {e}")
        return convert_question_to_sql_rule_based(question)

def convert_question_to_sql_rule_based(question):
    """ê·œì¹™ ê¸°ë°˜ SQL ë³€í™˜ (í´ë°±ìš©)"""
    question_lower = question.lower()

    # ê¸°ë³¸ì ì¸ íŒ¨í„´ ë§¤ì¹­ì„ í†µí•œ SQL ìƒì„±
    if "ê³ ê°" in question and "ëª©ë¡" in question:
        return "SELECT * FROM customers;"

    elif "ì‹ ìš©ì ìˆ˜" in question and "ë†’ì€" in question:
        return "SELECT c.name, cs.credit_score FROM customers c JOIN credit_scores cs ON c.customer_id = cs.customer_id ORDER BY cs.credit_score DESC;"

    elif "ì‹ ìš©ì ìˆ˜" in question and "ë‚®ì€" in question:
        return "SELECT c.name, cs.credit_score FROM customers c JOIN credit_scores cs ON c.customer_id = cs.customer_id ORDER BY cs.credit_score ASC;"

    elif "ë‚˜ì´" in question and "í‰ê· " in question:
        return "SELECT AVG(age) as average_age FROM customers;"

    elif "ì„±ë³„" in question and "ë¶„í¬" in question:
        return "SELECT gender, COUNT(*) as count FROM customers GROUP BY gender;"

    elif "ì†Œë“" in question and "ìˆ˜ì¤€" in question:
        return "SELECT income_level, COUNT(*) as count FROM customers GROUP BY income_level;"

    elif "ìœ„í—˜ë„" in question:
        return "SELECT cs.risk_level, COUNT(*) as count FROM credit_scores cs GROUP BY cs.risk_level;"

    elif "ê³ ê°" in question and "ìˆ˜" in question:
        return "SELECT COUNT(*) as total_customers FROM customers;"

    elif "ì‹ ìš©ì ìˆ˜" in question and "í‰ê· " in question:
        return "SELECT AVG(credit_score) as average_credit_score FROM credit_scores;"

    elif "ì§ì—…" in question and "ë³„" in question:
        return "SELECT occupation, COUNT(*) as count FROM customers GROUP BY occupation;"

    elif "ê°€ì…ì¼" in question and "ìµœê·¼" in question:
        return "SELECT name, registration_date FROM customers ORDER BY registration_date DESC LIMIT 5;"

    else:
        # ê¸°ë³¸ ì¿¼ë¦¬
        return "SELECT * FROM customers LIMIT 10;"

# RAG íŒŒì¼ ê´€ë¦¬ API ì—”ë“œí¬ì¸íŠ¸ë“¤

@app.route('/api/rag/domains', methods=['GET'])
def get_rag_domains():
    """RAG ë„ë©”ì¸ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return jsonify({
        'domains': RAG_DOMAINS,
        'allowed_extensions': list(ALLOWED_EXTENSIONS)
    })

@app.route('/api/rag/files/<domain>', methods=['GET'])
def get_rag_files(domain):
    """íŠ¹ì • ë„ë©”ì¸ì˜ RAG íŒŒì¼ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if domain not in RAG_DOMAINS:
        return jsonify({"error": "ìœ íš¨í•˜ì§€ ì•Šì€ ë„ë©”ì¸ì…ë‹ˆë‹¤."}), 400
    
    domain_path = os.path.join(UPLOAD_FOLDER, domain)
    files = []
    
    if os.path.exists(domain_path):
        for filename in os.listdir(domain_path):
            filepath = os.path.join(domain_path, filename)
            if os.path.isfile(filepath):
                files.append(get_file_info(filepath))
    
    return jsonify({
        'domain': domain,
        'domain_name': RAG_DOMAINS[domain],
        'files': files
    })

@app.route('/api/rag/upload/<domain>', methods=['POST'])
def upload_rag_file(domain):
    """íŠ¹ì • ë„ë©”ì¸ì— RAG íŒŒì¼ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤."""
    if domain not in RAG_DOMAINS:
        return jsonify({"error": "ìœ íš¨í•˜ì§€ ì•Šì€ ë„ë©”ì¸ì…ë‹ˆë‹¤."}), 400
    
    if 'file' not in request.files:
        return jsonify({"error": "íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."}), 400
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({"error": "íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400
    
    if not allowed_file(file.filename):
        return jsonify({"error": "í—ˆìš©ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤."}), 400
    
    try:
        filename = secure_filename(file.filename)
        domain_path = os.path.join(UPLOAD_FOLDER, domain)
        
        # ì¤‘ë³µ íŒŒì¼ëª… ì²˜ë¦¬
        base_name, extension = os.path.splitext(filename)
        counter = 1
        while os.path.exists(os.path.join(domain_path, filename)):
            filename = f"{base_name}_{counter}{extension}"
            counter += 1
        
        filepath = os.path.join(domain_path, filename)
        file.save(filepath)
        
        # ìƒˆë¡œìš´ RAG ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ì²˜ë¦¬
        result = rag_service.process_document(filepath, domain, filename)
        
        if result['success']:
            return jsonify({
                'message': 'íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ê³  ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.',
                'file': get_file_info(filepath),
                'rag_processing': result
            })
        else:
            return jsonify({
                'message': 'íŒŒì¼ì€ ì—…ë¡œë“œë˜ì—ˆì§€ë§Œ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
                'file': get_file_info(filepath),
                'rag_error': result['error']
            })
        
    except Exception as e:
        return jsonify({"error": f"íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}), 500

@app.route('/api/rag/delete/<domain>/<filename>', methods=['DELETE'])
def delete_rag_file(domain, filename):
    """íŠ¹ì • ë„ë©”ì¸ì—ì„œ RAG íŒŒì¼ì„ ì‚­ì œí•©ë‹ˆë‹¤."""
    if domain not in RAG_DOMAINS:
        return jsonify({"error": "ìœ íš¨í•˜ì§€ ì•Šì€ ë„ë©”ì¸ì…ë‹ˆë‹¤."}), 400
    
    try:
        filepath = os.path.join(UPLOAD_FOLDER, domain, filename)
        
        if not os.path.exists(filepath):
            return jsonify({"error": "íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404
        
        # ìƒˆë¡œìš´ RAG ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ë²¡í„° DBì—ì„œë„ ì‚­ì œ
        rag_result = rag_service.delete_document(domain, filename)
        
        # íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ ì‚­ì œ
        os.remove(filepath)
        
        if rag_result['success']:
            return jsonify({
                'message': 'íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.',
                'filename': filename,
                'rag_deletion': 'ì„±ê³µ'
            })
        else:
            return jsonify({
                'message': 'íŒŒì¼ì€ ì‚­ì œë˜ì—ˆì§€ë§Œ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‚­ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
                'filename': filename,
                'rag_error': rag_result['error']
            })
        
    except Exception as e:
        return jsonify({"error": f"íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}), 500

@app.route('/api/rag/download/<domain>/<filename>', methods=['GET'])
def download_rag_file(domain, filename):
    """íŠ¹ì • ë„ë©”ì¸ì—ì„œ RAG íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."""
    if domain not in RAG_DOMAINS:
        return jsonify({"error": "ìœ íš¨í•˜ì§€ ì•Šì€ ë„ë©”ì¸ì…ë‹ˆë‹¤."}), 400
    
    try:
        filepath = os.path.join(UPLOAD_FOLDER, domain, filename)
        
        if not os.path.exists(filepath):
            return jsonify({"error": "íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404
        
        # íŒŒì¼ ë‚´ìš©ì„ ì½ì–´ì„œ ë°˜í™˜ (ì‹¤ì œë¡œëŠ” send_fileì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŒ)
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        return jsonify({
            'filename': filename,
            'content': content,
            'file_info': get_file_info(filepath)
        })
        
    except Exception as e:
        return jsonify({"error": f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}), 500

@app.route('/api/rag/stats', methods=['GET'])
def get_rag_stats():
    """RAG ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        domain = request.args.get('domain', None)
        stats = rag_service.get_document_stats(domain)
        return jsonify(stats)
    except Exception as e:
        return jsonify({"error": f"í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}), 500

@app.route('/api/rag/search', methods=['POST'])
def search_rag_documents():
    """RAG ë¬¸ì„œì—ì„œ ê´€ë ¨ ì²­í¬ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    try:
        data = request.get_json()
        question = data.get('question', '')
        domain = data.get('domain', None)
        top_k = data.get('top_k', 5)
        
        if not question:
            return jsonify({"error": "ê²€ìƒ‰ ì§ˆë¬¸ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        chunks = rag_service.retrieve_relevant_chunks(question, domain, top_k)
        
        return jsonify({
            'question': question,
            'domain': domain,
            'chunks': chunks,
            'total_found': len(chunks)
        })
        
    except Exception as e:
        return jsonify({"error": f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}), 500

@app.route('/api/chat-history', methods=['GET'])
def get_chat_history():
    """ì±„íŒ… íˆìŠ¤í† ë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    # ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨
    return jsonify([])

@app.route('/api/rag/initialize', methods=['POST'])
def initialize_rag_manually():
    """RAG ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    try:
        results = initialize_rag_database()
        return jsonify({
            "success": True,
            "message": f"RAG ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ: {len(results)}ê°œ ë¬¸ì„œ ì²˜ë¦¬ë¨",
            "results": results
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/preprocessing/status', methods=['GET'])
def get_preprocessing_status():
    """ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸ API"""
    return jsonify({
        "korean_preprocessing_available": KOREAN_PREPROCESSING_AVAILABLE,
        "agent_loaded": korean_preprocessing_agent is not None,
        "domain_context": korean_preprocessing_agent.domain_context if korean_preprocessing_agent else None
    })

@app.route('/api/preprocessing/test', methods=['POST'])
def test_preprocessing():
    """ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸ API (í˜¼í•© ë°©ì‹ ìš°ì„ )"""
    try:
        data = request.get_json()
        test_query = data.get('query', '')
        
        if not test_query:
            return jsonify({"error": "í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400
        
        result = {}
        
        # í˜¼í•© ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸ (ìš°ì„ )
        if KOREAN_PREPROCESSING_AVAILABLE and korean_preprocessing_agent:
            try:
                preprocessed = korean_preprocessing_agent.preprocess_query(test_query)
                result["hybrid_preprocessing"] = {
                    "available": True,
                    "original_query": preprocessed["original_query"],
                    "normalized_query": preprocessed["normalized_query"],
                    "mapped_query": preprocessed["mapped_query"],
                    "entities": preprocessed["entities"],
                    "clauses": preprocessed["clauses"],
                    "reasoning_chain": preprocessed["reasoning_chain"],
                    "sql_mappings": preprocessed["sql_mappings"],
                    "preprocessing_metadata": preprocessed["preprocessing_metadata"],
                    "domain_terms_found": preprocessed["preprocessing_metadata"]["domain_terms_found"],
                    "clauses_count": preprocessed["preprocessing_metadata"]["clauses_count"],
                    "reasoning_steps": preprocessed["preprocessing_metadata"]["reasoning_steps"],
                    "sql_patterns_mapped": preprocessed["preprocessing_metadata"]["sql_patterns_mapped"]
                }
            except Exception as e:
                result["hybrid_preprocessing"] = {
                    "available": True,
                    "error": str(e)
                }
        else:
            result["hybrid_preprocessing"] = {
                "available": False,
                "reason": "í˜¼í•© ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }
        
        # í•œêµ­ì–´ ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸ (fallback)
        if KOREAN_PREPROCESSING_AVAILABLE and korean_preprocessing_agent:
            try:
                preprocessed = korean_preprocessing_agent.preprocess_query(test_query)
                result["korean_preprocessing"] = {
                    "available": True,
                    "original_query": preprocessed.original_query,
                    "normalized_query": preprocessed.normalized_query,
                    "clauses": [
                        {
                            "type": clause.type.value,
                            "content": clause.content,
                            "confidence": clause.confidence
                        } for clause in preprocessed.clauses
                    ],
                    "sql_keywords": preprocessed.sql_keywords,
                    "entities": preprocessed.entities,
                    "reasoning_steps": preprocessed.reasoning_steps,
                    "summary": korean_preprocessing_agent.get_clause_summary(preprocessed)
                }
            except Exception as e:
                result["korean_preprocessing"] = {
                    "available": True,
                    "error": str(e)
                }
        else:
            result["korean_preprocessing"] = {
                "available": False,
                "reason": "í•œêµ­ì–´ ì „ì²˜ë¦¬ ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# ë”•ì…”ë„ˆë¦¬ ê´€ë¦¬ API ì—”ë“œí¬ì¸íŠ¸ë“¤
@app.route('/api/dictionary/status', methods=['GET'])
def get_dictionary_status():
    """ë”•ì…”ë„ˆë¦¬ ìƒíƒœ í™•ì¸ API"""
    if not DICTIONARY_MANAGER_AVAILABLE or not dictionary_manager:
        return jsonify({
            "available": False,
            "reason": "ë™ì  ë”•ì…”ë„ˆë¦¬ ê´€ë¦¬ìë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        })
    
    stats = dictionary_manager.get_dictionary_stats()
    return jsonify({
        "available": True,
        "stats": stats,
        "timestamp": datetime.now().isoformat()
    })

@app.route('/api/dictionary/reload', methods=['POST'])
def reload_dictionaries():
    """ë”•ì…”ë„ˆë¦¬ ì¬ë¡œë“œ API"""
    if not DICTIONARY_MANAGER_AVAILABLE or not dictionary_manager:
        return jsonify({"error": "ë™ì  ë”•ì…”ë„ˆë¦¬ ê´€ë¦¬ìë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 400
    
    try:
        result = dictionary_manager.reload_dictionaries()
        return jsonify(result)
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/dictionary/backup', methods=['POST'])
def backup_dictionaries():
    """ë”•ì…”ë„ˆë¦¬ ë°±ì—… API"""
    if not DICTIONARY_MANAGER_AVAILABLE or not dictionary_manager:
        return jsonify({"error": "ë™ì  ë”•ì…”ë„ˆë¦¬ ê´€ë¦¬ìë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 400
    
    try:
        result = dictionary_manager.backup_dictionaries()
        return jsonify(result)
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/dictionary/terms', methods=['GET'])
def get_credit_terms():
    """ì‹ ìš©í‰ê°€ ë„ë©”ì¸ ìš©ì–´ ì¡°íšŒ API"""
    if not DICTIONARY_MANAGER_AVAILABLE or not dictionary_manager:
        return jsonify({"error": "ë™ì  ë”•ì…”ë„ˆë¦¬ ê´€ë¦¬ìë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 400
    
    try:
        return jsonify({
            "credit_terms": dictionary_manager.credit_terms,
            "timestamp": datetime.now().isoformat()
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/dictionary/terms/search', methods=['POST'])
def search_credit_terms():
    """ì‹ ìš©í‰ê°€ ë„ë©”ì¸ ìš©ì–´ ê²€ìƒ‰ API"""
    if not DICTIONARY_MANAGER_AVAILABLE or not dictionary_manager:
        return jsonify({"error": "ë™ì  ë”•ì…”ë„ˆë¦¬ ê´€ë¦¬ìë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 400
    
    try:
        data = request.get_json()
        query = data.get('query', '')
        
        if not query:
            return jsonify({"error": "ê²€ìƒ‰ì–´ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        results = dictionary_manager.search_terms(query)
        return jsonify({
            "query": query,
            "results": results,
            "total_found": len(results)
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/dictionary/terms', methods=['POST'])
def add_credit_term():
    """ì‹ ìš©í‰ê°€ ë„ë©”ì¸ ìš©ì–´ ì¶”ê°€ API"""
    if not DICTIONARY_MANAGER_AVAILABLE or not dictionary_manager:
        return jsonify({"error": "ë™ì  ë”•ì…”ë„ˆë¦¬ ê´€ë¦¬ìë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 400
    
    try:
        data = request.get_json()
        category = data.get('category', '')
        term = data.get('term', '')
        info = data.get('info', {})
        
        if not category or not term or not info:
            return jsonify({"error": "ì¹´í…Œê³ ë¦¬, ìš©ì–´, ì •ë³´ê°€ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        result = dictionary_manager.add_credit_term(category, term, info)
        return jsonify(result)
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/dictionary/terms/<category>/<term>', methods=['PUT'])
def update_credit_term(category, term):
    """ì‹ ìš©í‰ê°€ ë„ë©”ì¸ ìš©ì–´ ìˆ˜ì • API"""
    if not DICTIONARY_MANAGER_AVAILABLE or not dictionary_manager:
        return jsonify({"error": "ë™ì  ë”•ì…”ë„ˆë¦¬ ê´€ë¦¬ìë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 400
    
    try:
        data = request.get_json()
        info = data.get('info', {})
        
        if not info:
            return jsonify({"error": "ìˆ˜ì •í•  ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        result = dictionary_manager.update_credit_term(category, term, info)
        return jsonify(result)
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/dictionary/terms/<category>/<term>', methods=['DELETE'])
def delete_credit_term(category, term):
    """ì‹ ìš©í‰ê°€ ë„ë©”ì¸ ìš©ì–´ ì‚­ì œ API"""
    if not DICTIONARY_MANAGER_AVAILABLE or not dictionary_manager:
        return jsonify({"error": "ë™ì  ë”•ì…”ë„ˆë¦¬ ê´€ë¦¬ìë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 400
    
    try:
        result = dictionary_manager.delete_credit_term(category, term)
        return jsonify(result)
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/dictionary/sql-patterns', methods=['GET'])
def get_sql_patterns():
    """SQL íŒ¨í„´ ì¡°íšŒ API"""
    if not DICTIONARY_MANAGER_AVAILABLE or not dictionary_manager:
        return jsonify({"error": "ë™ì  ë”•ì…”ë„ˆë¦¬ ê´€ë¦¬ìë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 400
    
    try:
        return jsonify({
            "sql_patterns": dictionary_manager.sql_patterns,
            "timestamp": datetime.now().isoformat()
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/dictionary/sql-patterns', methods=['POST'])
def add_sql_pattern():
    """SQL íŒ¨í„´ ì¶”ê°€ API"""
    if not DICTIONARY_MANAGER_AVAILABLE or not dictionary_manager:
        return jsonify({"error": "ë™ì  ë”•ì…”ë„ˆë¦¬ ê´€ë¦¬ìë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 400
    
    try:
        data = request.get_json()
        category = data.get('category', '')
        korean = data.get('korean', '')
        sql = data.get('sql', '')
        
        if not category or not korean or not sql:
            return jsonify({"error": "ì¹´í…Œê³ ë¦¬, í•œêµ­ì–´, SQLì´ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        result = dictionary_manager.add_sql_pattern(category, korean, sql)
        return jsonify(result)
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/dictionary/sql-patterns/<category>/<korean>', methods=['PUT'])
def update_sql_pattern(category, korean):
    """SQL íŒ¨í„´ ìˆ˜ì • API"""
    if not DICTIONARY_MANAGER_AVAILABLE or not dictionary_manager:
        return jsonify({"error": "ë™ì  ë”•ì…”ë„ˆë¦¬ ê´€ë¦¬ìë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 400
    
    try:
        data = request.get_json()
        sql = data.get('sql', '')
        
        if not sql:
            return jsonify({"error": "ìˆ˜ì •í•  SQLì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        result = dictionary_manager.update_sql_pattern(category, korean, sql)
        return jsonify(result)
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/dictionary/sql-patterns/<category>/<korean>', methods=['DELETE'])
def delete_sql_pattern(category, korean):
    """SQL íŒ¨í„´ ì‚­ì œ API"""
    if not DICTIONARY_MANAGER_AVAILABLE or not dictionary_manager:
        return jsonify({"error": "ë™ì  ë”•ì…”ë„ˆë¦¬ ê´€ë¦¬ìë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 400
    
    try:
        result = dictionary_manager.delete_sql_pattern(category, korean)
        return jsonify(result)
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/dictionary/export', methods=['GET'])
def export_dictionary():
    """ë”•ì…”ë„ˆë¦¬ ë‚´ë³´ë‚´ê¸° API"""
    if not DICTIONARY_MANAGER_AVAILABLE or not dictionary_manager:
        return jsonify({"error": "ë™ì  ë”•ì…”ë„ˆë¦¬ ê´€ë¦¬ìë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 400
    
    try:
        format_type = request.args.get('format', 'json')
        result = dictionary_manager.export_dictionary(format_type)
        return jsonify(result)
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/dictionary/import', methods=['POST'])
def import_dictionary():
    """ë”•ì…”ë„ˆë¦¬ ê°€ì ¸ì˜¤ê¸° API"""
    if not DICTIONARY_MANAGER_AVAILABLE or not dictionary_manager:
        return jsonify({"error": "ë™ì  ë”•ì…”ë„ˆë¦¬ ê´€ë¦¬ìë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 400
    
    try:
        data = request.get_json()
        result = dictionary_manager.import_dictionary(data)
        return jsonify(result)
    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    print("OPENAI_API_KEY:", os.getenv('OPENAI_API_KEY'))
    app.run(debug=True, port=5000) 